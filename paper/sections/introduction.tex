\section{Introduction}
% Pages-size: 1
\label{sec: intro}
Sentiment analysis is a sub-domain within the field of Natural Language
Processing, in which an statistical model infers the direction and magnitude of
emotions from text. Successful inference depends on building appropriate
language models which can model the structural dependencies and semantics within
the sentences of a language sufficiently. Context and word order are [relevant]
to capturing a word or phrase's semantic representation. For instance if the
model has been trained on partial phrases, it could become more common for the
model to make wrong inferences based on ignored negations. For this reason, it
is the goal of this paper to investigate the role of such dependencies. The
paper will investigate the importance of word order and context by studying a
number of different models, each varying in how granular information is parsed.
% TODO: Reflow the bracketed text
\begin{enumerate}
    \item \textbf{How important is word order for the task of classification of
    sentiment?} Some models, such as the traditional Bag of Words, disregard
    word order in favour of a simpler vector representation of the underlying
    text. Long short-term memory (LSTM), a more recent variant on the Recurrent
    Neural Network, maintains a memory state of recent words encountered to
    incorporate word-order of short and long distances. This paper initially
    believes that models which maintain and understand word-order will perform
    better. 
    % TODO: Do something about the findings
    \item \textbf{Does tree structure improve the accuracy as opposed to
    sequential learning?} Vanilla LSTM as originally introduced, behaves in a
    sequential manner. One alternative to LSTM proposed was Tree LSTM, which can
    use multiple prior cells to infer the state of the current word, [enhancing
    the context available for the model]. The paper seeks to investigate whether
    adding these additional precursor cells for each prediction, will actually
    increase performance of the inference on the testing. The original belief is
    that this will certainly be the case, and as the results suggest, this
    [seems to be case].
    % TODO: Add cite for sequential introduction TODO: Add cite for tree
    % introduction TODO: Reflow bracketed text. TODO: Is this significant?
    \item \textbf{Performance on supervising sentiment per node?}
    % This paper is seeking to investigate if the Tree LSTM algorithm should be
    % trained on the supervision of the sentiment of individual words, or on the
    % sentiment of the sentences altogether. 
    This paper is seeking to investigate whether adding additional supervision
    on intermediate words or phrases will help the model capture the more
    context-related sentiment. The initial hypothesis of this paper argues that
    the supervision of individual nodes might decrease performance, due to less
    context to account for negating sentiment, for instance.
    % TODO: @Gongze, do you agree with the above initial hypothesis and
    % reasoning? ||| I want to add that the supervision is acted upon not only
    % word level, rather on a phrase level. And also the later result might
    % suggest a neutral effect of adding supervision, that is, no big gap
    % between these two cases. I suspect its because we dont train it with proper
    % learning rate or not until they converge. |||TODO: Incorporate later
    % results.
    \item \textbf{Will the performance vary much on different sentence length across models?}
    % A model's performance might depend on how many words the model needs to keep
    % in store. Decreasing the sentence length might show the difference in model
    % performance, and which model relatively performs better with longer
    % sentences. Initially, this paper argues that Tree LSTM might perform the
    % best, as it has more cells to infer relevant knowledge from than regular
    % LSTM. 
    A model may behave very differently to sentences of different length,
    because for longer sentences the sentiment semantics is more complex and
    sometimes contradict itself in different parts. So it is a crucial problem
    whether a model performs evenly on different length sentences and whether
    some model performs better on capturing sentiments contexts in longer time
    scale. Initially, this paper argues that Tree LSTM might perform the best,
    as it process the context in a hand-crafted structural way, thus more
    efficient when dealing with long-scale semantics.
    % TODO: @Gongze, do you agree with the initial hypothesis? TODO: Add results
    % Might have inproper grammar and usage of word.
    \item \textbf{How does N-ary Tree LSTM compare to the Child-Sum Tree LSTM?}
    The N-ary tree-LSTM differs with Child-sum tree-LSTM in that the latter is
    [agnostic] of the order of the child nodes. On implementation details, the
    N-ary tree-LSTM has different gate parameter for each child, while Child-sum
    use the same parameter for all the gate including forget gate. In most
    cases, N-ary tree-LSTM first project then sum, while the Child-sum tree-LSTM
    do the opposite. Hence they are suitable to different tasks: the N-ary
    tree-LSTM is suitable to those trees where child nodes are ordered, and the
    Child-sum tree-LSTM should work well on the order of child nodes does not
    contribute to the context. In the sentiment classification task, we need
    N-ary tree-LSTM since the word order is important to context extraction.
\end{enumerate}

In order to do so, the different models mentioned will be initialized with
300-dimensional GloVe\cite{pennington2014glove} vectors. The goal is to predict
the sentiment of [Stanford Sentiment Treebank data], with the different settings
corresponding to the [aforementioned research questions].
% SST doesn't have a paper to cite, weird.