{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "plt.style.use('default')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install humanize\n",
        "import psutil, humanize\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free:\" + humanize.naturalsize( psutil.virtual_memory().available ), \"| Proc size:\" + humanize.naturalsize( process.memory_info().rss))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class MutePrint:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.stdout_restore = sys.stdout\n",
        "    # Disable\n",
        "\n",
        "    def blockPrint(self):\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    # Restore\n",
        "    def enablePrint(self):\n",
        "        sys.stdout = self.stdout_restore\n",
        "mute = MutePrint()\n",
        "# %%\n",
        "!wget http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -O trainDevTestTrees_PTB.zip\n",
        "!unzip trainDevTestTrees_PTB.zip"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install pytreebank\n",
        "import pytreebank\n",
        "# %%\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p | grep cudart.so | sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "# if accelerator == 'cpu':\n",
        "#   raise InvalidArgumentError('should run this notebook under gpu enviroment')\n",
        "# !pip install torch torchvision"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!cp \"/gdrive/My Drive/glove.840B.300d.sst.txt\" ."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!wget -q https://github.com/JMitnik/NLP-Lab2/raw/cg/main.py -O ./main.py\n",
        "!wget -q https://github.com/JMitnik/NLP-Lab2/raw/cg/utils.py -O ./utils.py"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mute.blockPrint()\n",
        "from main import *\n",
        "from utils import *\n",
        "mute.enablePrint()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_subtree_dataset():\n",
        "    '''\n",
        "    extract all subtrees together to the exact form of the `train_data` used in last ipynb\n",
        "    args: None\n",
        "    returns: a list contains three list of Examples, each of them corresponds to one of 'train', 'test', 'dev' set\n",
        "    '''\n",
        "    dataset = pytreebank.load_sst(\"./trees\")\n",
        "    datasets = dataset.values()\n",
        "    print(dataset.keys())\n",
        "    results = []\n",
        "    for D in datasets:\n",
        "        result = []\n",
        "        for tree in D:\n",
        "            tree.lowercase()\n",
        "            for c in tree.all_children():\n",
        "                sc = str(c)\n",
        "                trans = transitions_from_treestring(sc)\n",
        "                label = c.label\n",
        "                tree = c\n",
        "                tokens = tokens_from_treestring(sc)\n",
        "                result.append(Example(tokens=tokens, tree=tree, label=label, transitions=trans))\n",
        "        results.append(result)\n",
        "    return results"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "subtree_train_data, subtree_test_data, subtree_dev_data = get_subtree_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class Experiment():\n",
        "\n",
        "    def __init__(self, model, optimizer, *args, **kwargs):\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "    def train(self):\n",
        "        path = \"{}.pt\".format(self.kwargs['exp_name'] if 'exp_name' in self.kwargs else self.model.__class__.__name__)\n",
        "        if os.path.exists(path):\n",
        "            ckpt= torch.load(path)\n",
        "            self.model.load_state_dict(ckpt[\"state_dict\"])\n",
        "            return\n",
        "        self.losses, self.accs = train_model(self.model, self.optimizer, *self.args, **self.kwargs)\n",
        "    def eval(self, eval_fn=None, data=test_data, **kwargs):\n",
        "        if eval_fn is None:\n",
        "            if not ('eval_fn' in kwargs):\n",
        "                eval_fn = simple_evaluate\n",
        "            else:\n",
        "                eval_fn = self.kwargs['eval_fn']\n",
        "        self.pred, _, _, self.acc = eval_fn(self.model, data, **kwargs)\n",
        "        return \n",
        "\n",
        "    def plot(self):\n",
        "        plt.plot(self.losses)\n",
        "        plt.plot(self.accs)\n",
        "        return\n",
        "\n",
        "    def get_accuracy():\n",
        "        return self.accs\n",
        "\n",
        "    def get_losses():\n",
        "        return self.losses"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# build all the experiments by feeding corresponding parameters\n",
        "# cant think of cleaner way to do it :(\n",
        "from collections import namedtuple\n",
        "ExperimentModel = namedtuple(\"ExperimentModel\", [\"name\", \"modelclass\" ,\"lr\", \"options\", \"parameters\"])\n",
        "\n",
        "models = [\n",
        "#     ExperimentModel(\"bow\", BOW, 5e-4,\n",
        "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
        "#         [vocab_size, n_classes, v]\n",
        "#     ),\n",
        "#     ExperimentModel(\"cbow\", CBOW, 5e-4, \n",
        "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
        "#         [len(v.w2i), embedding_dim, len(t2i), v]\n",
        "#     ),\n",
        "#     ExperimentModel(\"deep_cbow\", DeepCBOW, 5e-4,\n",
        "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
        "#         [len(v.w2i), embedding_dim, hidden_dim, len(t2i), v]\n",
        "#    ),\n",
        "#     ExperimentModel(\"pt_deep_cbow\", DeepCBOW, 5e-4,\n",
        "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
        "#         [len(nv.w2i), embedding_dim, hidden_dim, len(t2i), nv]\n",
        "#    ),\n",
        "#     ExperimentModel(\"lstm\", LSTMClassifier, 3e-4,\n",
        "#         dict(num_iterations=25000, print_every=250, eval_every=1000),\n",
        "#         [len(nv.w2i), 300, 168, len(t2i), nv]\n",
        "#    ),\n",
        "#     ExperimentModel(\"mini_lstm\", LSTMClassifier, 2e-4,\n",
        "#         dict(num_iterations=30000,\n",
        "#                   print_every=250, eval_every=250,\n",
        "#                   batch_size=batch_size,\n",
        "#                   batch_fn=get_minibatch,\n",
        "#                   prep_fn=prepare_minibatch,\n",
        "#                   eval_fn=evaluate\n",
        "#         ),\n",
        "#         [len(nv.w2i), 300, 168, len(t2i), nv]\n",
        "#     ),\n",
        "    ExperimentModel(\"tree_lstm\", TreeLSTMClassifier, 2e-4,\n",
        "       dict(num_iterations=30000,\n",
        "           print_every=250, eval_every=250,\n",
        "           prep_fn=prepare_treelstm_minibatch,\n",
        "           eval_fn=evaluate,\n",
        "           batch_fn=get_minibatch,\n",
        "           batch_size=25, eval_batch_size=25),\n",
        "        [len(nv.w2i), 300, 150, len(t2i), nv]\n",
        "   )\n",
        "#     ExperimentModel(\"subtree_lstm\", TreeLSTMClassifier, 2e-4,\n",
        "#        dict(num_iterations=30000,\n",
        "#               print_every=250, eval_every=250,\n",
        "#               prep_fn=prepare_treelstm_minibatch,\n",
        "#               eval_fn=evaluate,\n",
        "#               batch_fn=get_minibatch,\n",
        "#               batch_size=25, eval_batch_size=25, train_data=subtree_train_data),\n",
        "#         [len(nv.w2i), 300, 150, len(t2i), nv]\n",
        "#    )\n",
        "]\n",
        "!cp /gdrive/My\\ Drive/pts/*.pt ./\n",
        "\n",
        "def do_experiment(rd_seed, experiment_models, train_embed=False):\n",
        "    torch.cuda.manual_seed(rd_seed)\n",
        "    np.random.seed(rd_seed)\n",
        "    for exp_model in experiment_models:\n",
        "        # build a new tree lstm for feeding subtree\n",
        "        model = exp_model.modelclass(*exp_model.parameters)\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=exp_model.lr)\n",
        "        if exp_model.name.startswith('pt') or exp_model.name.endswith('lstm'):\n",
        "            with torch.no_grad():\n",
        "                model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
        "\n",
        "                if not train_embed:\n",
        "                    model.embed.weight.requires_grad = False\n",
        "        \n",
        "        path_embed_string = \"_train_embed\" if train_embed else \"\"\n",
        "        exp = Experiment(model, optimizer, exp_name='{}_rd_seed_{}{}'.format(\n",
        "            exp_model.name, rd_seed, path_embed_string), **exp_model.options)\n",
        "        exp.train()\n",
        "        yield exp"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rd_s_li = [7, 42, 1984]\n",
        "exp_li = []\n",
        "for rs_s in rd_s_li:\n",
        "    exp_li.append(list(do_experiment(rs_s)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "!cp ./*.pt \"/gdrive/My Drive/pts\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install prettytable\n",
        "import prettytable as pt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "def generate_tables():\n",
        "    models_eval_results = {}\n",
        "    for rd, el in zip(rd_s_li, *exp_li):\n",
        "        for n, exp in zip(model_name_li, el):\n",
        "            prep_func = prepare_treelstm_minibatch if n.startswith(\n",
        "                'tree') or n.startswith('subtree') else prepare_minibatch\n",
        "            exp.eval(eval_fn=evaluate_with_results, batch_fn=get_minibatch,\n",
        "                    prep_fn=prep_func)\n",
        "            pred_and_acc = [exp.pred, exp.acc]\n",
        "            models_eval_results[n] = [pred_and_acc] if not models_eval_results.get(\n",
        "                n) else models_eval_results[n].append([pred_and_acc])\n",
        "    acc_table = pt.PrettyTable()\n",
        "    acc_table.field_names = model_name_li\n",
        "    def helper(x):\n",
        "        y = [e[1] for e in x]\n",
        "        m = np.mean(y)\n",
        "        v = np.std(y)\n",
        "        s = '{}+-{}'.format(m, v)\n",
        "        return s\n",
        "    acc_table.add_row([helper(models_eval_results[n]) for n in model_name_li])\n",
        "    sig_table = pt.PrettyTable()\n",
        "    sig_table.field_names = ['models']+model_name_li\n",
        "    for n1 in model_name_li:\n",
        "        row = [n1]\n",
        "        for n2 in model_name_li:\n",
        "            sig = sign_test(models_eval_results[n1][0][0], models_eval_results[n2][0][0])\n",
        "            row.append(sig)\n",
        "        sig_table.add_row(row)\n",
        "    return acc_table, sig_table"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "acc_table, sig_table = generate_tables()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(acc_table)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(sig_table)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "def load_shared_files():\n",
        "  file_id = \"1az0y5LU2T7vrhc3AVpVgfZthp7kAJUqH\"\n",
        "  files = drive.ListFile({'q': \"'%s' in parents and trashed=false\" % file_id}).GetList()\n",
        "  for f in files:\n",
        "    print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "    fname = os.path.join('', f['title'])\n",
        "    print('downloading to {}'.format(fname))\n",
        "    f_ = drive.CreateFile({'id': f['id']})\n",
        "    f_.GetContentFile(fname)\n",
        "  \n",
        "load_shared_files()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from itertools import groupby\n",
        "\n",
        "def prep_bin(data, bin_size):\n",
        "    \"\"\" Returns a bin \"\"\"\n",
        "    max_line_length = max([len(example.tokens) for example in data])\n",
        "    sorted_data = sorted(data, key=lambda x: len(x.tokens))\n",
        "    bins = []\n",
        "    \n",
        "    for key, group in groupby(sorted_data, lambda x: len(x.tokens)):\n",
        "        bins.append(list(group))\n",
        "        \n",
        "    return bins\n",
        "\n",
        "def split_data_on_sentlen(data, sent_len_split=20):\n",
        "    \"\"\"Splits data into two parts, based on `sent_len_split`\"\"\"\n",
        "    result_l = []\n",
        "    result_r = []\n",
        "\n",
        "    for example in data:\n",
        "        if len(example.tokens) < sent_len_split:\n",
        "            result_l.append(example)\n",
        "        else:\n",
        "            result_r.append(example)\n",
        "    \n",
        "    return [result_l, result_r]\n",
        "\n",
        "\n",
        "# BE SURE TO MAKE SURE TO COPY AL .ct files!\n",
        "# %%\n",
        "def sent_len_evaluate(model, data,  batch_fn=get_minibatch, bin_size=5 , prep_fn=prepare_minibatch, **kwargs):\n",
        "    \"\"\"Evaluates a model for different sentence sizes.\n",
        "        - Data: Example[]\n",
        "        - Model: Trained Model\n",
        "        - prep_fn: Method to turn Example into tensor\n",
        "    \"\"\"\n",
        "    set_trace()\n",
        "    binned_data = split_data_on_sentlen(data, 20)\n",
        "    results = []\n",
        "\n",
        "    for index, examples in enumerate(binned_data):\n",
        "        pred, _, _, acc = evaluate_with_results(model, examples, batch_fn, prep_fn)\n",
        "        results.append(acc)\n",
        "    \n",
        "    # Results is not exaclty correct, as eval expects only one result, but this indicates the results for each 'bin' atm\n",
        "    return _, _, _, results\n",
        "    # bin = list of entries, where each entry is mapped to corresponding sent\n",
        "    # length"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exp2 = next(do_experiment(7, models))\n",
        "# FOR TREE\n",
        "# exp.eval(eval_fn=sent_len_evaluate, batch_fn=get_minibatch,\n",
        "#                     prep_fn=prepare_treelstm_minibatch)\n",
        "\n",
        "# For MINI_LSTM\n",
        "exp2.eval(eval_fn=sent_len_evaluate, batch_fn=get_minibatch,\n",
        "                    prep_fn=prepare_minibatch)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}