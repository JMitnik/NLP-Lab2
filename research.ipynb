{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:03:17.994707Z",
     "start_time": "2018-12-12T17:03:16.194423Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:02:28.393987Z",
     "start_time": "2018-12-12T17:02:25.230375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: humanize in /Users/jonathanmitnik/anaconda3/lib/python3.6/site-packages (0.5.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install humanize\n",
    "import psutil, humanize\n",
    "def printm():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  print(\"Gen RAM Free:\" + humanize.naturalsize( psutil.virtual_memory().available ), \"| Proc size:\" + humanize.naturalsize( process.memory_info().rss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:05:59.937219Z",
     "start_time": "2018-12-12T17:03:18.163026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-12 18:03:18--  http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip [following]\n",
      "--2018-12-12 18:03:18--  https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 789539 (771K) [application/zip]\n",
      "Saving to: 'trainDevTestTrees_PTB.zip'\n",
      "\n",
      "trainDevTestTrees_P 100%[===================>] 771.03K   660KB/s    in 1.2s    \n",
      "\n",
      "2018-12-12 18:03:20 (660 KB/s) - 'trainDevTestTrees_PTB.zip' saved [789539/789539]\n",
      "\n",
      "Archive:  trainDevTestTrees_PTB.zip\n",
      "replace trees/dev.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "class MutePrint:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stdout_restore = sys.stdout\n",
    "    # Disable\n",
    "\n",
    "    def blockPrint(self):\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    # Restore\n",
    "    def enablePrint(self):\n",
    "        sys.stdout = self.stdout_restore\n",
    "mute = MutePrint()\n",
    "# %%\n",
    "!wget http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -O trainDevTestTrees_PTB.zip\n",
    "!unzip trainDevTestTrees_PTB.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T17:02:30.406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytreebank\n",
      "  Downloading https://files.pythonhosted.org/packages/69/b5/ee153b218cbfe39cad162f12fdb29dc46f69ee8748849575c166b6a29c7b/pytreebank-0.2.4.tar.gz\n",
      "Building wheels for collected packages: pytreebank\n",
      "  Running setup.py bdist_wheel for pytreebank ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/jonathanmitnik/Library/Caches/pip/wheels/14/a7/e5/79ced57f7bf9d4f3f6fc020456e3d8e045907a87cb16a0544e\n",
      "Successfully built pytreebank\n",
      "Installing collected packages: pytreebank\n",
      "Successfully installed pytreebank-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pytreebank\n",
    "import pytreebank\n",
    "# %%\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p | grep cudart.so | sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "# if accelerator == 'cpu':\n",
    "#   raise InvalidArgumentError('should run this notebook under gpu enviroment')\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T17:02:34.978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "!cp \"/gdrive/My Drive/glove.840B.300d.sst.txt\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-12-12T17:03:25.002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://github.com/JMitnik/NLP-Lab2/raw/cg/main.py -O ./main.py\n",
    "!wget -q https://github.com/JMitnik/NLP-Lab2/raw/cg/utils.py -O ./utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:03:07.479808Z",
     "start_time": "2018-12-12T17:03:07.292850Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mute' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d751c7252b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblockPrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menablePrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mute' is not defined"
     ]
    }
   ],
   "source": [
    "mute.blockPrint()\n",
    "from main import *\n",
    "from utils import *\n",
    "mute.enablePrint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subtree_dataset():\n",
    "    '''\n",
    "    extract all subtrees together to the exact form of the `train_data` used in last ipynb\n",
    "    args: None\n",
    "    returns: a list contains three list of Examples, each of them corresponds to one of 'train', 'test', 'dev' set\n",
    "    '''\n",
    "    dataset = pytreebank.load_sst(\"./trees\")\n",
    "    datasets = dataset.values()\n",
    "    print(dataset.keys())\n",
    "    results = []\n",
    "    for D in datasets:\n",
    "        result = []\n",
    "        for tree in D:\n",
    "            tree.lowercase()\n",
    "            for c in tree.all_children():\n",
    "                sc = str(c)\n",
    "                trans = transitions_from_treestring(sc)\n",
    "                label = c.label\n",
    "                tree = c\n",
    "                tokens = tokens_from_treestring(sc)\n",
    "                result.append(Example(tokens=tokens, tree=tree, label=label, transitions=trans))\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subtree_train_data, subtree_test_data, subtree_dev_data = get_subtree_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experiment():\n",
    "\n",
    "    def __init__(self, model, optimizer, *args, **kwargs):\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "    def train(self):\n",
    "        path = \"{}.pt\".format(self.kwargs['exp_name'] if 'exp_name' in self.kwargs else self.model.__class__.__name__)\n",
    "        if os.path.exists(path):\n",
    "            ckpt= torch.load(path)\n",
    "            self.model.load_state_dict(ckpt[\"state_dict\"])\n",
    "            return\n",
    "        self.losses, self.accs = train_model(self.model, self.optimizer, *self.args, **self.kwargs)\n",
    "    def eval(self, eval_fn=None, data=test_data, **kwargs):\n",
    "        if eval_fn is None:\n",
    "            if not ('eval_fn' in kwargs):\n",
    "                eval_fn = simple_evaluate\n",
    "            else:\n",
    "                eval_fn = self.kwargs['eval_fn']\n",
    "        self.pred, _, _, self.acc = eval_fn(self.model, data, **kwargs)\n",
    "        return \n",
    "\n",
    "    def plot(self):\n",
    "        plt.plot(self.losses)\n",
    "        plt.plot(self.accs)\n",
    "        return\n",
    "\n",
    "    def get_accuracy():\n",
    "        return self.accs\n",
    "\n",
    "    def get_losses():\n",
    "        return self.losses\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T17:09:20.456943Z",
     "start_time": "2018-12-12T17:09:20.047807Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TreeLSTMClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a443202d4455>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#         [len(nv.w2i), 300, 168, len(t2i), nv]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#     ),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     ExperimentModel(\"tree_lstm\", TreeLSTMClassifier, 2e-4,\n\u001b[0m\u001b[1;32m     38\u001b[0m        dict(num_iterations=30000,\n\u001b[1;32m     39\u001b[0m            \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TreeLSTMClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# build all the experiments by feeding corresponding parameters\n",
    "# cant think of cleaner way to do it :(\n",
    "from collections import namedtuple\n",
    "ExperimentModel = namedtuple(\"ExperimentModel\", [\"name\", \"modelclass\" ,\"lr\", \"options\", \"parameters\"])\n",
    "\n",
    "models = [\n",
    "#     ExperimentModel(\"bow\", BOW, 5e-4,\n",
    "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
    "#         [vocab_size, n_classes, v]\n",
    "#     ),\n",
    "#     ExperimentModel(\"cbow\", CBOW, 5e-4, \n",
    "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
    "#         [len(v.w2i), embedding_dim, len(t2i), v]\n",
    "#     ),\n",
    "#     ExperimentModel(\"deep_cbow\", DeepCBOW, 5e-4,\n",
    "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
    "#         [len(v.w2i), embedding_dim, hidden_dim, len(t2i), v]\n",
    "#    ),\n",
    "#     ExperimentModel(\"pt_deep_cbow\", DeepCBOW, 5e-4,\n",
    "#         dict(num_iterations=30000, print_every=1000, eval_every=1000),\n",
    "#         [len(nv.w2i), embedding_dim, hidden_dim, len(t2i), nv]\n",
    "#    ),\n",
    "#     ExperimentModel(\"lstm\", LSTMClassifier, 3e-4,\n",
    "#         dict(num_iterations=25000, print_every=250, eval_every=1000),\n",
    "#         [len(nv.w2i), 300, 168, len(t2i), nv]\n",
    "#    ),\n",
    "#     ExperimentModel(\"mini_lstm\", LSTMClassifier, 2e-4,\n",
    "#         dict(num_iterations=30000,\n",
    "#                   print_every=250, eval_every=250,\n",
    "#                   batch_size=batch_size,\n",
    "#                   batch_fn=get_minibatch,\n",
    "#                   prep_fn=prepare_minibatch,\n",
    "#                   eval_fn=evaluate\n",
    "#         ),\n",
    "#         [len(nv.w2i), 300, 168, len(t2i), nv]\n",
    "#     ),\n",
    "    ExperimentModel(\"tree_lstm\", TreeLSTMClassifier, 2e-4,\n",
    "       dict(num_iterations=30000,\n",
    "           print_every=250, eval_every=250,\n",
    "           prep_fn=prepare_treelstm_minibatch,\n",
    "           eval_fn=evaluate,\n",
    "           batch_fn=get_minibatch,\n",
    "           batch_size=25, eval_batch_size=25),\n",
    "        [len(nv.w2i), 300, 150, len(t2i), nv]\n",
    "   )\n",
    "#     ExperimentModel(\"subtree_lstm\", TreeLSTMClassifier, 2e-4,\n",
    "#        dict(num_iterations=30000,\n",
    "#               print_every=250, eval_every=250,\n",
    "#               prep_fn=prepare_treelstm_minibatch,\n",
    "#               eval_fn=evaluate,\n",
    "#               batch_fn=get_minibatch,\n",
    "#               batch_size=25, eval_batch_size=25, train_data=subtree_train_data),\n",
    "#         [len(nv.w2i), 300, 150, len(t2i), nv]\n",
    "#    )\n",
    "]\n",
    "!cp /gdrive/My\\ Drive/pts/*.pt ./\n",
    "\n",
    "def do_experiment(rd_seed, experiment_models, train_embed=False):\n",
    "    torch.cuda.manual_seed(rd_seed)\n",
    "    np.random.seed(rd_seed)\n",
    "    for exp_model in experiment_models:\n",
    "        # build a new tree lstm for feeding subtree\n",
    "        model = exp_model.modelclass(exp_model.parameters)\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=exp_model.lr)\n",
    "        if exp_model.name.startswith('pt') or exp_model.name.endswith('lstm'):\n",
    "            with torch.no_grad():\n",
    "                model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "\n",
    "                if not train_embed:\n",
    "                    model.embed.weight.requires_grad = False\n",
    "        \n",
    "        path_embed_string = \"train_embed\" if train_embed else \"not_train_embed\"\n",
    "        exp = Experiment(model, optimizer, exp_name='{}_rd_seed_{}_{}'.format(\n",
    "            n, rd_seed, path_embed_string), **exp_model.options)\n",
    "        exp.train()\n",
    "        yield exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd_s_li = [7, 42, 1984]\n",
    "exp_li = []\n",
    "for rs_s in rd_s_li:\n",
    "    exp_li.append(list(do_experiment(rs_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!cp ./*.pt \"/gdrive/My Drive/pts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install prettytable\n",
    "import prettytable as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_tables():\n",
    "    models_eval_results = {}\n",
    "    for rd, el in zip(rd_s_li, *exp_li):\n",
    "        for n, exp in zip(model_name_li, el):\n",
    "            prep_func = prepare_treelstm_minibatch if n.startswith(\n",
    "                'tree') or n.startswith('subtree') else prepare_minibatch\n",
    "            exp.eval(eval_fn=evaluate_with_results, batch_fn=get_minibatch,\n",
    "                    prep_fn=prep_func)\n",
    "            pred_and_acc = [exp.pred, exp.acc]\n",
    "            models_eval_results[n] = [pred_and_acc] if not models_eval_results.get(\n",
    "                n) else models_eval_results[n].append([pred_and_acc])\n",
    "    acc_table = pt.PrettyTable()\n",
    "    acc_table.field_names = model_name_li\n",
    "    def helper(x):\n",
    "        y = [e[1] for e in x]\n",
    "        m = np.mean(y)\n",
    "        v = np.std(y)\n",
    "        s = '{}+-{}'.format(m, v)\n",
    "        return s\n",
    "    acc_table.add_row([helper(models_eval_results[n]) for n in model_name_li])\n",
    "    sig_table = pt.PrettyTable()\n",
    "    sig_table.field_names = ['models']+model_name_li\n",
    "    for n1 in model_name_li:\n",
    "        row = [n1]\n",
    "        for n2 in model_name_li:\n",
    "            sig = sign_test(models_eval_results[n1][0][0], models_eval_results[n2][0][0])\n",
    "            row.append(sig)\n",
    "        sig_table.add_row(row)\n",
    "    return acc_table, sig_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "acc_table, sig_table = generate_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(acc_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sig_table)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
